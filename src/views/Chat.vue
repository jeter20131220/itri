<script setup>
import { ref, nextTick, computed, onMounted, watch, onBeforeUnmount, onUnmounted } from "vue";
import { useRoute } from 'vue-router'
import "animate.css";
import axios from "axios";
import { v4 as uuidv4 } from 'uuid'
import Swal from "sweetalert2"

const route = useRoute()

function generateChatId() {
  console.log(`chat_${Date.now()}_${uuidv4()}`)
  return `chat_${Date.now()}_${uuidv4()}`
}

// generateChatId();

const chatId = ref(localStorage.getItem('chat_id') || generateChatId())

const isMobileLandscape = ref(false)

const isDesktopPortrait = ref(false)

const inputText = ref("");
const fileInput = ref(null);
const previewImage = ref(null);
const selectedFile = ref(null);
const inConversation = ref(true);
const messages = ref([]);
const isListening = ref(false)
const showSidebar = ref(false);
const isDesktop = ref(false);
const isVideoMode = ref(true) // â† ä½ å¯ä»¥ç”¨ route æˆ–ç•«é¢åˆ‡æ›ä¾†æ§åˆ¶
const activeConversationIndex = ref(0);
let isVideoPause = ref(true);
let videoLoading = ref(false);
let isAudioPlaying = ref(false); // éŸ³è¨Šæ’­æ”¾ç‹€æ…‹

const isReversed = ref(false)

const isPortrait = computed(() => route.query.o === 'p')

const selectedCharacter = ref('äººç‰©1');

function isMobileDevice() {
  return /Android|iPhone|iPad|iPod/i.test(navigator.userAgent)
}

const checkOrientation = () => {
  const isLandscape = window.innerWidth > window.innerHeight
  const isPortrait = !isLandscape

  // è§£æç¶²å€åƒæ•¸ï¼ˆæ”¯æ´ #/? æ ¼å¼ï¼‰
  const hashParams = new URLSearchParams(window.location.hash.split("?")[1])
  const oParam = hashParams.get("o")
  const userId = hashParams.get("userid") || "default1"

  // åˆ¤æ–·æ˜¯å¦ç‚ºæ‰‹æ©Ÿ
  const isMobile = /Android|iPhone|iPad|iPod/i.test(navigator.userAgent)
  const isMobileLandscapeNow = isMobile && isLandscape
  const isMobilePortraitNow = isMobile && isPortrait

  console.log("ğŸ§­ ç‹€æ…‹åµæ¸¬ï¼š", {
    oParam,
    isMobile,
    isLandscape,
    isMobileLandscapeNow,
    isMobilePortraitNow,
  })

  // æ¡Œæ©Ÿ or ç­†é›» + o=p æ™‚æé†’ä½¿ç”¨æ©«ç‰ˆé€£çµ
  if (!isMobile && oParam === "p") {
    isDesktopPortrait.value = !isMobile && oParam === 'p'
    // Swal.fire({
    //   title: "ğŸ’» å»ºè­°ä½¿ç”¨æ©«å‘ç‰ˆé é¢",
    //   html: `
    //     <p style="font-size:15px; color:#444; line-height:1.6; text-align:left;">
    //       æ‚¨ç›®å‰æ­£åœ¨ä½¿ç”¨ <b>æ¡Œæ©Ÿæˆ–ç­†é›»</b> ç‰ˆæœ¬ç€è¦½ã€‚<br><br>
    //       ç‚ºäº†ç²å¾—æ›´ä½³çš„ç•«é¢èˆ‡äº’å‹•é«”é©—ï¼Œ<br>
    //       å»ºè­°æ‚¨ä½¿ç”¨ä»¥ä¸‹é€£çµé–‹å•Ÿæ©«å‘ç‰ˆé é¢ï¼š<br><br>
    //       <a href="https://cmm.ai/nfachat/#/?userid=${userId}&o=l"
    //         style="color:#2563eb; text-decoration:underline; font-weight:500;">
    //         ğŸ‘‰ é»æˆ‘å‰å¾€æ©«ç‰ˆé é¢
    //       </a>
    //     </p>
    //   `,
    //   icon: "info",
    //   confirmButtonText: "æˆ‘çŸ¥é“äº†",
    //   confirmButtonColor: "#2563eb",
    //   allowOutsideClick: false,
    //   allowEscapeKey: false,
    //   backdrop: true,
    // })
    // return
  }

  // æ‰‹æ©Ÿç›´å‘ + o=l æ™‚æé†’æ©«æ”¾
  if (isMobile && oParam === "l" && isPortrait) {
    Swal.fire({
      title: "ğŸ“± è«‹æ©«æ”¾æ‰‹æ©Ÿ",
      html: `
        <p style="font-size:15px; color:#444; line-height:1.6;">
          ç‚ºäº†æ›´å¥½çš„è§€çœ‹é«”é©—ï¼Œè«‹å°‡æ‰‹æ©Ÿæ—‹è½‰æˆæ©«å‘æ¨¡å¼ã€‚<br>
          è‹¥æ‚¨çš„æ‰‹æ©Ÿé–‹å•Ÿäº† <b>ç›´å‘é–å®š</b>ï¼Œè«‹å…ˆå°‡å…¶é—œé–‰ã€‚
        </p>
      `,
      icon: "info",
      confirmButtonText: "æˆ‘çŸ¥é“äº†",
      confirmButtonColor: "#2563eb",
      allowOutsideClick: false,
      allowEscapeKey: false,
      backdrop: true,
    })
    return
  }

  // å…¶ä»–æƒ…æ³ä¸é¡¯ç¤ºå½ˆçª—
  Swal.close()
}

const userId = computed(() => route.query.userid)

console.log(userId.value);


// onMounted(() => {
//   checkOrientation()
//   window.addEventListener('resize', checkOrientation)
// })

onBeforeUnmount(() => {
  window.removeEventListener('resize', checkOrientation)
})

watch(chatId, (newVal) => {
  localStorage.setItem('chat_id', newVal)
})

function toggleLayout() {
  isReversed.value = !isReversed.value
}

const chatData = ref([]);

const cohatDataTitle = ref([]);

const hisMessages = []

const fetchChatHistory = async () => {

  try {
    const res = await axios.get(`https://cmm.ai:8066/history?user_id=${userId.value}&chat_id=all`)
    console.log('å–å¾—æ­·å²ç´€éŒ„ï¼š', res.data)
    chatData.value = res.data;
    console.log('å–å¾—æ­·å²ç´€éŒ„é™£åˆ—ï¼š', chatData.value)


    const transformedChats = chatData.value.map(chat => {
      const chatId = chat.chat_id
      const title = chat.title
      const messages = []

      chat.data.forEach(item => {
        messages.push({
          author: "user",
          label: "text",
          text: item.question
        })

        messages.push({
          author: "bot",
          label: "text",
          answer: item.answer,
          table: item.table
        })
      })

      return {
        chat_id: chatId,
        title: title,
        messages: messages
      }
    })

    console.log(transformedChats)

    conversations.value = transformedChats;

    conversations.value.unshift({
      chat_id: generateChatId(),
      title: "New Chat",
      messages: [
        {
          author: "bot",
          label: "text",
          answer: "æ‚¨å¥½ï¼Œé€™è£¡æ˜¯æ¶ˆé˜²ç½²ç½å®³çµ±è¨ˆå°åŠ©æ‰‹ï¼Œæ‚¨å¯ä»¥è©¢å•ä¾‹å¦‚ï¼šã€Œ2023å¹´å“ªå€‹æœˆä»½é«˜å±±ç—‡æœ€å¤šï¼Ÿã€æˆ–ã€Œè¿‘å…©å¹´å“ªå€‹ç¸£å¸‚è¿·è·¯æœ€å¤šï¼Ÿã€è«‹å•æ‚¨æƒ³æŸ¥è©¢ä»€éº¼å‘¢ï¼Ÿ",
        }

      ]
    });

  } catch (err) {
    console.error('éŒ¯èª¤ï¼š', err)
  }
}

const currentMessages = computed(() =>
  conversations.value[activeConversationIndex.value].messages
);

function selectConversation(index) {



  activeConversationIndex.value = index;
  console.log('chatid', chatId.value, conversations.value[activeConversationIndex.value])
  chatId.value = conversations.value[activeConversationIndex.value].chat_id;


  console.log(activeConversationIndex.value)
}

function startNewConversation() {
  chatId.value = generateChatId()
  conversations.value.push({
    title: "New Chat",
    messages: []
  });
  activeConversationIndex.value = conversations.value.length - 1;

  console.log('è¼‰å…¥å®Œ', conversations.values)
}

let video = ref(null);

const videoSpeakSources = ref([]); // å‹•å˜´å‹å½±ç‰‡
const videoSources = ref([]); // é–‹å ´ç™½å½±ç‰‡(ä¸­)

// videoSources.value = ["https://cmm.ai/itri_rescue/Q2/mute.mp4"];

// videoSpeakSources.value = ["https://cmm.ai/itri_rescue/Q2/speak_s.mp4"];



const loadVideoSources = async () => {
  videoSources.value = ["https://cmm.ai/itri_rescue/cache_Q/mute.mp4"];

  videoSpeakSources.value = ["https://cmm.ai/itri_rescue/cache_Q/speak_s.mp4"];

};


// ğŸ” ç•¶äººç‰©åˆ‡æ›æ™‚ï¼Œæ›´æ–° videoSources & videoSpeakSources
watch(selectedCharacter, (newVal) => {
  if (newVal === 'äººç‰©1') {
    videoSources.value = ["https://cmm.ai/itri_rescue/cache_Q/mute.mp4"];
    videoSpeakSources.value = ["https://cmm.ai/itri_rescue/cache_Q/speak_s.mp4"];
    videoSrc.value = videoSources.value;
    console.log(videoSrc.value)
    videoPlay();

  } else if (newVal === 'äººç‰©2') {
    videoSources.value = ["https://cmm.ai/itri_rescue/Q2/mute.mp4"];
    videoSpeakSources.value = ["https://cmm.ai/itri_rescue/Q2/speak_s.mp4"];
    videoSrc.value = videoSources.value;

    console.log(newVal)
    console.log(videoSrc.value)

    videoPlay();


  }
});


videoSpeakSources.value = [
  new URL("@/assets/img/speak_s.mp4", import.meta.url).href,
];

const videoSrc = ref('');



const conversations = ref([
  {
    title: "New Chat",
    messages: []
  }
]);



const isMuted = ref(true) // ä¸€é–‹å§‹æ˜¯éœéŸ³

const triggerFileInput = () => {
  fileInput.value?.click();
};

const handleFileChange = (event) => {
  const file = event.target.files[0];
  if (file && file.type.startsWith("image/")) {
    const reader = new FileReader();
    reader.onload = (e) => {
      previewImage.value = e.target.result;
      selectedFile.value = file;
    };
    reader.readAsDataURL(file);
  }
};

const clearFile = () => {
  selectedFile.value = null;
  previewImage.value = null;
  if (fileInput.value) fileInput.value.value = "";
};





onMounted(() => {
  fetchChatHistory()
  loadVideoSources();
  checkOrientation()
  window.addEventListener('resize', checkOrientation)
  videoSrc.value = videoSources.value;
  videoPlay();
  // åµæ¸¬æ˜¯å¦ç‚ºæ¡Œæ©Ÿæ¨¡å¼
  const update = () => {
    isDesktop.value = window.innerWidth >= 768;

    // if (isDesktop.value) showSidebar.value = true;
    // else showSidebar.value = false;
  };

  console.log('ç•¶å‰å°è©±', conversations.value,)
  console.log(' activeConversationIndex.value', conversations.value)


  // setTimeout(() => {
  //   conversations.value[activeConversationIndex.value].messages.push({
  //     author: "bot",
  //     label: "text",
  //     answer: "æ‚¨å¥½ï¼Œé€™è£¡æ˜¯æ¶ˆé˜²ç½²ç½å®³çµ±è¨ˆå°åŠ©æ‰‹ï¼Œæ‚¨å¯ä»¥è©¢å•ä¾‹å¦‚ï¼šã€Œ2023å¹´å“ªå€‹æœˆä»½é«˜å±±ç—‡æœ€å¤šï¼Ÿã€æˆ–ã€Œè¿‘å…©å¹´å“ªå€‹ç¸£å¸‚è¿·è·¯æœ€å¤šï¼Ÿã€è«‹å•æ‚¨æƒ³æŸ¥è©¢ä»€éº¼å‘¢ï¼Ÿ",

  //   });
  // }, 500);

  update();
  window.addEventListener('resize', update);

});
// const handleEnter = async () => {
//   if (inputText.value.trim()) {
//     messages.value.push({
//       label: "text",
//       author: "user",
//       text: inputText.value.trim(),
//       image: previewImage.value,
//     });
//     console.log(messages.value)
//     messages.value.push({
//       label: "text",
//       author: "ai",
//       text: "chatæ¸¬è©¦",
//     });
//     inputText.value = "";
//     clearFile();
//     if (!inConversation.value) inConversation.value = true;
//     await nextTick();
//     scrollToBottom();
//   }
// };

let messageinput

const handleEnter = async () => {
  console.log(chatId.value);

  if (!inputText.value.trim()) return;
  conversations.value[activeConversationIndex.value].messages.push({
    author: "user",
    label: "text",
    text: inputText.value
  });

  console.log(conversations.value)
  messageinput = inputText.value;
  inputText.value = "";
  // å¯ä»¥åœ¨é€™è£¡æ¨¡æ“¬ä¸€å€‹ bot å›è¦†
  let url = `https://cmm.ai:8066/ask?question=${messageinput}&chat_id=${chatId.value}&user_id=${userId.value}`;
  console.log(url)
  try {
    const response = await axios.post(url);
    if (response.status === 200) {
      console.log(response.data)
      console.log(response.data.mp4_url)
      if (response?.data?.mp4_url) {
        if (currentAudio.value) {
          currentAudio.value.pause();
          currentAudio.value.currentTime = 0;
          currentAudio.value = null;
        }
        video.loop = false;
        isMuted.value = false;
        // æ ¹æ“šç›®å‰äººç‰©åˆ‡æ›ä¾†æºï¼Œæ±ºå®šç”¨ mp4_url é‚„æ˜¯ mp4_url2
        if (selectedCharacter.value === 'äººç‰©1') {
          videoSrc.value = response.data.mp4_url;
        } else if (selectedCharacter.value === 'äººç‰©2') {
          console.log(selectedCharacter.value)
          videoSrc.value = `https://cmm.ai/itri_rescue/Q2/` + response.data.mp4_url2;
        }
        videoPlay();


      } else {
        const audioUrl = response.data.mp3_url;
        audioPlay(audioUrl);
        videoSrc.value = videoSpeakSources.value;
        videoPlay();

      }


      console.log(videoSrc.value)
      // videoPlay();
      setTimeout(() => {
        conversations.value[activeConversationIndex.value].messages.push({
          author: "bot",
          label: "text",
          answer: response.data.answer,
          table: response.data.table
        });
      }, 500);


    }
  } catch (error) {
    console.error("âŒ ç™¼ç”ŸéŒ¯èª¤ï¼š", error);
  }

  if (!inConversation.value) inConversation.value = true;
  await nextTick();
  scrollToBottom();
}

// const scrollToBottom = () => {
//   window.scrollTo({ top: document.body.scrollHeight, behavior: "smooth" });
// };


const chatArea = ref(null); // å°è©±æ¡†

// æ»¾å‹•åˆ°å°è©±æ¡†åº•éƒ¨
const scrollToBottom = () => {
  setTimeout(() => {
    console.log("chatArea.value", chatArea.value.scrollHeight);

    chatArea.value.scrollTo({
      top: chatArea.value.scrollHeight,
      behavior: "smooth",
    });
  }, 100);
};







const toggleSidebar = () => {
  showSidebar.value = !showSidebar.value;
};

// let recognition

// if ('webkitSpeechRecognition' in window) {
//   const SpeechRecognition = window.webkitSpeechRecognition
//   recognition = new SpeechRecognition()
//   recognition.continuous = false
//   recognition.lang = 'zh-TW' // æˆ– en-US
//   recognition.interimResults = false

//   recognition.onstart = () => {
//     isListening.value = true
//   }

//   recognition.onend = () => {
//     isListening.value = false
//   }

//   recognition.onresult = (event) => {
//     const transcript = event.results[0][0].transcript
//     inputText.value += transcript
//     handleEnter()
//   }
// } else {
//   console.warn('é€™å€‹ç€è¦½å™¨ä¸æ”¯æ´èªéŸ³è¾¨è­˜')
// }

// function startListening() {
//   if (!recognition) return
//   recognition.start()
// }
let recognition

if ('webkitSpeechRecognition' in window) {
  const SpeechRecognition = window.webkitSpeechRecognition
  recognition = new SpeechRecognition()
  recognition.continuous = false
  recognition.lang = 'zh-TW'
  recognition.interimResults = true // âœ… é–‹å•Ÿå³æ™‚è¾¨è­˜

  recognition.onstart = () => {
    isListening.value = true
  }

  recognition.onend = () => {
    isListening.value = false
  }

  recognition.onresult = (event) => {
    let interimTranscript = ''
    let finalTranscript = ''

    for (let i = event.resultIndex; i < event.results.length; ++i) {
      const transcript = event.results[i][0].transcript
      if (event.results[i].isFinal) {
        finalTranscript += transcript
      } else {
        interimTranscript += transcript
      }
    }

    // é¡¯ç¤ºæš«æ™‚æ–‡å­—ï¼ˆå³æ™‚é¡¯ç¤ºè¾¨è­˜ä¸­å…§å®¹ï¼‰
    inputText.value = finalTranscript + interimTranscript

    // å¦‚æœå·²ç¶“æ˜¯æœ€çµ‚çµæœ â†’ å‘¼å« handleEnter()
    if (finalTranscript) {
      handleEnter()
    }
  }
} else {
  console.warn('é€™å€‹ç€è¦½å™¨ä¸æ”¯æ´èªéŸ³è¾¨è­˜')
}

function startListening() {
  if (!recognition) return
  recognition.start()
}

watch(conversations.value, (val) => {
  console.log("messages", val);
  scrollToBottom();
});




const audioURL = ref(null);

let currentAudio = ref(null); // ç•¶å‰éŸ³è¨Š

// å½±ç‰‡æ’­æ”¾çµæŸè§¸ç™¼
const onVideoEnded = () => {
  console.log("æ’­æ”¾é»é ­å½±ç‰‡");
  console.log("ç•¶å‰å½±ç‰‡", currentAudio.value);
  // æ¸…ç©ºéŸ³è¨Š
  if (currentAudio.value) {
    currentAudio.value.pause();
    currentAudio.value.currentTime = 0;
    currentAudio.value = null;
  }
  video.loop = true
  // æ’­æ”¾é»é ­å½±ç‰‡
  videoSrc.value = videoSources.value;
  // video.value.loop = true; // è¨­ç½®å¾ªç’°æ’­æ”¾
  videoPlay();
  isVideoPause.value = true;
};

function audioPlay(audioUrl) {
  if (currentAudio.value) {
    currentAudio.value.pause();
    currentAudio.value.currentTime = 0;
  }
  // æ’­æ”¾éŸ³æª”
  currentAudio.value = new Audio(audioUrl);
  setTimeout(() => {
    currentAudio.value.play(); // æ’­æ”¾éŸ³è¨Š
    isVideoPause.value = true;
  }, 1000);

  // ç›£è½éŸ³è¨Šæ’­æ”¾çµæŸ
  currentAudio.value.addEventListener("ended", onAudioEnded);
  // ç›£è½éŸ³è¨Šæ’­æ”¾ç‹€æ…‹
  currentAudio.value.addEventListener("play", onAudioPlay);
  currentAudio.value.addEventListener("pause", onAudioPause);


}

// éŸ³è¨ŠçµæŸå¾Œæš«åœå½±ç‰‡æ’­æ”¾
const onAudioEnded = () => {
  // æ¸…ç©ºéŸ³è¨Š
  if (currentAudio.value) {
    currentAudio.value.pause();
    currentAudio.value.currentTime = 0;
    currentAudio.value = null;
  }

  // æ’­æ”¾é»é ­å½±ç‰‡
  videoSrc.value = videoSources.value;
  // video.value.loop = true; // è¨­ç½®å¾ªç’°æ’­æ”¾
  videoPlay();


};

// åˆ¤æ–·éŸ³è¨Šæ˜¯å¦ç‚ºæ’­æ”¾ç‹€æ…‹
const onAudioPlay = () => {
  isAudioPlaying.value = true;
  console.log("isAudioPlaying.value", isAudioPlaying.value);
};

const onAudioPause = () => {
  isAudioPlaying.value = false;
  isVideoPause.value = false;
  console.log("isAudioPlaying.value", isAudioPlaying.value);


};



onMounted(() => {
  window.addEventListener("resize", checkOrientation)
})

onUnmounted(() => {
  window.removeEventListener("resize", checkOrientation)
})

function videoPlay() {
  if (video.value) {
    video.value.load();
    video.value.play();
  }
}

// AI ä¸»æ’­å½±ç‰‡æ’­æ”¾ & æš«åœ
function togglePause(val) {
  if (val === "pause") {
    // video.value.pause();
    isVideoPause.value = false;

    if (video.value) {
      video.value.pause();
    }
    if (currentAudio.value) {
      currentAudio.value.pause(); // æš«åœéŸ³è¨Š
    }
  } else {
    isVideoPause.value = true;

    if (video.value) {
      video.value.play();
    }

    if (currentAudio.value) {
      currentAudio.value.play(); // æ’­æ”¾éŸ³è¨Š
      currentAudio.value.addEventListener("ended", onAudioEnded);
    }
  }
}

const playbackSpeed = ref('1')

function updatePlaybackRate() {
  if (video.value) {
    const rate = parseFloat(playbackSpeed.value)
    video.value.pause()            // å…ˆæš«åœ
    video.value.currentTime = 0    // å›åˆ°é–‹é ­ï¼ˆå¦‚æœä½ å¸Œæœ›å¾é ­é–‹å§‹æ’­ï¼‰
    video.value.playbackRate = rate
    video.value.play()             // é‡æ–°æ’­æ”¾
  }
}

function bindVideoEvents() {
  if (video.value) {
    video.value.addEventListener("loadedmetadata", () => {
      updatePlaybackRate()
    })
  }
}

// åµæ¸¬ video å…ƒç´ è®ŠåŒ–ï¼ˆåˆ‡æ›å½±ç‰‡ src å¾Œ video æœƒ reloadï¼‰
watch(video, () => {
  bindVideoEvents()
})


</script>

<template>
  <!-- æ¼¢å ¡æŒ‰éˆ•ï¼ˆåƒ…åœ¨ video æ¨¡å¼é¡¯ç¤ºï¼‰ -->
  <button v-if="isVideoMode" :class="[
    'absolute top-4 z-50 transition-all duration-300',
    showSidebar ? 'left-52' : 'left-4'
  ]" @click="toggleSidebar">
    <svg class="w-8 h-8 text-white bg-[#345678] p-1 rounded" fill="none" stroke="currentColor" viewBox="0 0 24 24">
      <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 6h16M4 12h16M4 18h16" />
    </svg>
  </button>
  <button @click="toggleLayout" v-if="!isPortrait"
    class="hidden md:flex fixed top-10 left-1/2 z-50 transform -translate-x-1/2 -translate-y-1/2 bg-gray-200 hover:bg-gray-300 text-gray-800 px-4 py-2 rounded shadow">
    <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor"
      class="size-6">
      <path stroke-linecap="round" stroke-linejoin="round"
        d="M7.5 21 3 16.5m0 0L7.5 12M3 16.5h13.5m0-13.5L21 7.5m0 0L16.5 12M21 7.5H7.5" />
    </svg>
  </button>
  <audio v-if="audioURL" :src="audioURL" controls></audio>
  <!-- å¤–å±¤å®¹å™¨ï¼Œå·¦å³åˆ†æ¬„ -->
  <div class="flex h-screen transition-all duration-300" :class="{
    'w-full': !isDesktopPortrait,    // å…¶ä»–æƒ…æ³ç¶­æŒæ»¿ç‰ˆ
    'w-2/5 mx-auto': isDesktopPortrait, // æ¡Œæ©Ÿ + o=p æ™‚ 50% ä¸¦ç½®ä¸­
  }">
    <div v-if="!isVideoMode || showSidebar"
      class="fixed top-0 left-0 h-screen w-64 bg-[#345678] flex flex-col text-white z-40 transition-transform duration-300"
      :style="{ display: isVideoMode && !showSidebar ? 'none' : 'flex' }">
      <div class="p-4 text-lg font-semibold border-b border-white/20">
        æ­·å²ç´€éŒ„<br>
      </div>

      <div class="flex-1 overflow-y-auto">
        <div v-for="(conversation, index) in conversations" :key="index" @click="selectConversation(index)"
          class="px-4 py-3 hover:bg-[#3e6b95] cursor-pointer transition-colors" :class="{
            'bg-[#3e6b95]': index === activeConversationIndex
          }">
          {{ conversation.title }}
        </div>
      </div>

      <div class="p-4 border-t border-white/20">
        <button class="w-full bg-white text-[#345678] py-2 rounded hover:bg-gray-200 transition"
          @click="startNewConversation">
          + æ–°è¦–çª—
        </button>
      </div>
    </div>
    <div :class="[
      'flex w-full h-screen',
      isPortrait ? 'flex-col' : (isReversed ? 'flex-row-reverse' : 'flex-row')
    ]">
      <!-- å·¦å´ï¼šè™›æ“¬äººå½±ç‰‡å€ -->
      <div :class="[
        isPortrait ? 'h-1/2 w-full' : 'h-full w-1/2',
        'bg-gray-100 flex items-center justify-center bg-[#F5F5F5] relative'
      ]">
        <!-- å¯æ”¾ iframe / video tag / canvas -->
        <!-- <video src="" autoplay muted loop class="w-full h-full object-cover"></video> -->
        <video ref="video" preload playsinline autoplay :muted="isMuted" @ended="onVideoEnded" :class="[
          'mx-auto object-cover transition-all duration-300',
          isMobileLandscape ? 'h-[90%]' : 'h-[100%]',
          isDesktopPortrait ? 'w-[40%]' : 'w-[65%]'
        ]">
          <source :src="videoSrc" type="video/mp4" />
        </video>
        <button v-if="isVideoPause" @click="togglePause('pause')" class="control-btn bg-[#345678]"
          :class="isDesktopPortrait ? 'right-[50px]' : 'right-[150px]'">
          <img src="../assets/img/pause-button.png" alt="" />
        </button>

        <button v-else @click="togglePause('play')" class="control-btn bg-[#345678]"
          :class="isDesktopPortrait ? 'right-[50px]' : 'right-[150px]'">
          <img src="../assets/img/play-button.png" alt="" />
        </button>
        <div class="absolute left-4 bottom-4 bg-[#345678] text-white rounded px-2 py-1 text-sm z-10">
          <select v-model="playbackSpeed" @change="updatePlaybackRate" class="bg-transparent text-white border-none outline-none appearance-none
           [&>option]:text-black [&>option]:bg-white">
            <!-- <option value="0.6">æ›´æ…¢</option> -->
            <option value="0.75">æ…¢</option>
            <option value="1">ä¸€èˆ¬</option>
            <option value="1.25">å¿«</option>
          </select>
        </div>
        <div class="absolute right-4 bottom-4 bg-[#345678] text-white rounded px-2 py-1 text-sm z-10">
          <select v-model="selectedCharacter" class="bg-transparent text-white border-none outline-none appearance-none
           [&>option]:text-black [&>option]:bg-white">
            <option value="äººç‰©1">äººç‰©1</option>
            <option value="äººç‰©2">äººç‰©2</option>
          </select>
        </div>
      </div>

      <!-- å³å´ï¼šè¡¨æ ¼èˆ‡å°è©±å€ -->
      <div
        :class="[isReversed ? 'md:ml-8' : '', isPortrait ? 'h-1/2 w-full' : 'h-full w-1/2', 'flex flex-col  md:pt-0 bg-white min-h-0']">
        <!-- å°è©±èˆ‡è¡¨æ ¼å…§å®¹ -->
        <div v-if="inConversation" ref="chatArea" class="flex-1 overflow-y-auto p-4 space-y-6 h-auto">
          <div v-for="(msg, idx) in currentMessages" :key="idx" class="space-y-2">
            <div v-if="msg.label === 'text'" class="message animate__animated flex" :class="{
              'justify-end': msg.author === 'user',
              'justify-start': msg.author !== 'user',
              animate__fadeInRight: msg.author === 'user',
              animate__fadeInLeft: msg.author !== 'user'
            }">
              <div class="px-5 py-3 transition-all duration-300" :class="[
                msg.author === 'user' && 'bg-main text-white shadow-lg rounded-full',
                isMobileLandscape ? 'max-w-[100%]' : 'max-w-[90%] sm:max-w-[70%]'
              ]">
                <div v-if="msg.text">
                  <p v-html="msg.text"></p>
                </div>
                <div v-if="msg.answer" class="mt-2" v-html="msg.answer"></div>
                <div v-if="msg.table" class="mt-2" v-html="msg.table"></div>
              </div>
            </div>
          </div>
        </div>

        <!-- ä¸‹æ–¹è¼¸å…¥å€ -->
        <div v-if="inConversation" class="sticky bottom-0 bg-white p-5 flex items-end gap-2">
          <div class="relative flex-1">
            <textarea v-model="inputText" @keydown.enter.prevent="handleEnter" @keydown.shift.enter.stop rows="1"
              placeholder="è¼¸å…¥è¨Šæ¯..." class="w-full p-5 border border-gray-300 rounded-xl resize-none pr-10"></textarea>

            <!-- èªéŸ³è¼¸å…¥æŒ‰éˆ• -->
            <button class="px-4 py-3 absolute right-14"
              :class="isListening ? 'text-red-500 animate-pulse' : 'text-gray-600'" style="bottom: 15px"
              @click="startListening">
              <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5"
                stroke="currentColor" class="size-6">
                <path stroke-linecap="round" stroke-linejoin="round"
                  d="M12 18.75a6 6 0 0 0 6-6v-1.5m-6 7.5a6 6 0 0 1-6-6v-1.5m6 7.5v3.75m-3.75 0h7.5M12 15.75a3 3 0 0 1-3-3V4.5a3 3 0 1 1 6 0v8.25a3 3 0 0 1-3 3Z" />
              </svg>
            </button>

            <!-- é€å‡ºæŒ‰éˆ• -->
            <button @click="handleEnter"
              class="px-4 py-3 absolute right-3 text-white bg-main hover:opacity-75 transition-opacity duration-300 rounded-full shadow cursor-pointer"
              style="bottom: 15px">
              â¤
            </button>
          </div>

          <input ref="fileInput" type="file" accept="image/*" @change="handleFileChange" class="hidden" />
          <button @click="triggerFileInput" class="text-gray-600 hover:text-blue-500">
            <!-- <PaperClipIcon class="w-6 h-6" /> -->
          </button>
        </div>
      </div>
    </div>
  </div>
</template>


<style lang="scss">
h2 {
  margin-top: 30px;
}

table {
  width: 100%;
  border-collapse: collapse;
  margin-top: 10px;
  max-width: 90%;
}

table,
th,
td {
  border: 1px solid #ccc;
}

th,
td {
  padding: 10px;
  text-align: left;
}

th {
  background-color: #f0f0f0;
}

.message-out {
  margin-left: auto;
  // background: #D61718;
  // color: white;
}

.message-in {
  margin-right: auto;
  // background: #fff;
  // color: black;

}

.control-btn {
  width: 33px;
  height: 33px;
  display: flex;
  align-items: center;
  justify-content: center;
  position: absolute;
  z-index: 50;
  top: 23px;
  // right: 150px;
  cursor: pointer;
  border: none;
  border-radius: 100px;

  img {
    width: 25px;
    filter: invert(100%) sepia(0%) saturate(0%) hue-rotate(93deg) brightness(103%) contrast(103%);
  }

  @media (max-width: 768px) {
    top: 16px;
    right: 16px;
  }

  @media (max-width: 1080px) and (aspect-ratio: 9/16) {
    width: 66px;
    height: 66px;
    top: 23px;
    right: 50px;

    img {
      width: 50px;
    }
  }
}

@media screen and (max-aspect-ratio: 1/1) {
  .portrait-stack {
    flex-direction: column !important;
  }
}
</style>
